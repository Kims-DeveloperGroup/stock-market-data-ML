{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import FinanceDataReader as fdr\n",
    "import csv\n",
    "import numpy as np\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "fdr.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(data_list, file_name):\n",
    "    with open(file_name,'w', newline='') as f:\n",
    "        data_list = np.array(data_list)\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(data_list)\n",
    "    return\n",
    "\n",
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "def extract_x_and_y(data, sequence_length):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    time_stamp_y = []\n",
    "    for i in range(0, len(data) - sequence_length + 1):\n",
    "        x = data[i:i + sequence_length]\n",
    "        y_index = i + sequence_length\n",
    "        if y_index < len(data):\n",
    "            y = data[y_index]\n",
    "            time_stamp_y.append(data[y_index, [0]])\n",
    "            data_y.append(y)\n",
    "        data_x.append(x)\n",
    "    return np.array(data_x), np.array(data_y), np.array(time_stamp_y), data\n",
    "\n",
    "def extract_x_and_y_for_training(data, sequence_length):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    time_stamp_y = []\n",
    "    for i in range(0, len(data) - sequence_length):\n",
    "        x = data[i:i + sequence_length]\n",
    "        y_index = i + sequence_length\n",
    "        y = data[y_index]\n",
    "        \n",
    "        time_stamp_y.append(data[y_index, [0]])\n",
    "        data_x.append(x)\n",
    "        data_y.append(y)\n",
    "    return np.array(data_x), np.array(data_y), np.array(time_stamp_y)\n",
    "\n",
    "def lstm_cell(hidden_size):\n",
    "    cell = rnn.BasicLSTMCell(hidden_size, state_is_tuple=True)\n",
    "    return cell\n",
    "\n",
    "def getDailyStockPriceData(code, startDate, endDate, sequence_length, isTraining = False):\n",
    "    data = np.array(fdr.DataReader(code, startDate, endDate))\n",
    "    data = MinMaxScaler(data[:, 0:-1]) #시작가격, 최고가, 최적가, 종가, 거래량\n",
    "    if isTraining == False:\n",
    "        return extract_x_and_y(data, sequence_length)\n",
    "    else:\n",
    "        return extract_x_and_y_for_training(data, sequence_length)\n",
    "\n",
    "def getActualDailyPrices(code, startDate, endDate):\n",
    "    data = np.array(fdr.DataReader(code, startDate, endDate))\n",
    "    return MinMaxScaler(data[:, :-1])\n",
    "\n",
    "def get_predict_data_of_last_date(x, sess):\n",
    "    outputs = sess.run(Y_pred, feed_dict={X: x})\n",
    "    return outputs[-1:]\n",
    "\n",
    "def retrain_with_outputs(data, x_data, sequence_length, addtional_batch_count, sess):\n",
    "    print(\"data: {} x_data {}\".format(data.shape, x_data.shape))\n",
    "    for i in range(0, addtional_batch_count):\n",
    "        predict_of_last = get_predict_data_of_last_date(x_data, sess)\n",
    "        data = np.append(data, predict_of_last, axis=0)\n",
    "        x_data , y_data ,_ ,_ = extract_x_and_y(data, sequence_length)\n",
    "    print(\"result: {} {}\".format(x_data.shape, y_data.shape))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTestData(code, end_date_of_test_data, start_date_to_predict, end_date_to_predict, sequence_length, sess):\n",
    "    print(\"Run test data. code: {}  {} ~ {}\".format(code, start_date_to_predict, end_date_to_predict))\n",
    "    \n",
    "    actual_y = getActualDailyPrices(code, start_date_to_predict, end_date_to_predict)\n",
    "    days_to_predict = len(actual_y)\n",
    "    print(\"length of days to predict: {}\".format(days_to_predict))\n",
    "    \n",
    "    test_data_x, test_data_y, test_data_time_stamp_y, data = getDailyStockPriceData(code, '1992-01-01', end_date_of_test_data, sequence_length, False)\n",
    "    outputs = retrain_with_outputs(data, test_data_x, sequence_length, days_to_predict, sess)\n",
    "    expected_prices = actual_y[:, 3:4]\n",
    "    predict_prices = outputs[-days_to_predict:, 3:4]\n",
    "    \n",
    "    plt.title(\"Actual vs Predicted\")\n",
    "    plt.plot(expected_prices)\n",
    "    plt.plot(predict_prices)\n",
    "    plt.xlabel(\"Time Period\")\n",
    "    plt.ylabel(\"Stock Price\")\n",
    "    plt.show()\n",
    "    \n",
    "    rmse_val = sess.run(rmse, feed_dict={expected_results: actual_y, predictions: outputs[-days_to_predict:,]})\n",
    "    print(\"RMSE: {} \\n\\n\".format(rmse_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(code_to_train, start_date, end_date, sequence_length, learning_rate = 0.01, train_iteration_count = 1000, sess = tf.Session()):\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    #Hyper Params\n",
    "    data_dim = 5\n",
    "    hidden_dim = 10\n",
    "    num_classes = 5\n",
    "    batch_size = None\n",
    "    \n",
    "    global X, Y, Y_pred, cells, loss, train_op, expected_results, predictions, rmse\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, [batch_size, sequence_length, data_dim])\n",
    "    Y = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "    \n",
    "    cells = rnn.MultiRNNCell([lstm_cell(hidden_dim) for _ in range(2)], state_is_tuple=True)\n",
    "    outputs, _states = tf.nn.dynamic_rnn(cells, X, dtype=tf.float32)\n",
    "\n",
    "    # FC layer\n",
    "    X_for_fc = tf.reshape(outputs, [-1, hidden_dim])\n",
    "    outputs = tf.contrib.layers.fully_connected(X_for_fc, num_classes, activation_fn=tf.tanh)\n",
    "    # reshape out for sequence_loss\n",
    "    outputs = tf.reshape(outputs, [-1, sequence_length, num_classes])\n",
    "\n",
    "    # We use the last cell's output\n",
    "    Y_pred = outputs[:, -1]\n",
    "\n",
    "    loss = tf.reduce_sum(tf.square(Y_pred[:, 3] - Y[:, 3]))\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "    \n",
    "    # RMSE\n",
    "    expected_results = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "    predictions = tf.placeholder(tf.float32, [batch_size, num_classes])\n",
    "    rmse = tf.reduce_sum(tf.square(expected_results[:, 3] - predictions[:, 3]))\n",
    "    \n",
    "    #Training Set #1\n",
    "    data_x, data_y, time_stamp_y = getDailyStockPriceData(code_to_train, start_date, end_date, sequence_length, True)\n",
    "    training_set = [[data_x, data_y]]\n",
    "    \n",
    "    \n",
    "    #Run training\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    ckpt_path = './trained_checkpoint/daily_stock_prediction_model_{}.ckpt'.format(code_to_train)\n",
    "    try:\n",
    "        saver.restore(sess, ckpt_path)\n",
    "    except Exception as e:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    init_loss = 100\n",
    "    for t in range (0, len(training_set)):\n",
    "        print(\"training set #\", t)\n",
    "        x = training_set[t][0]\n",
    "        y = training_set[t][1]\n",
    "        print(\"x shape: {}\".format(x.shape))\n",
    "        print(\"y shape: {}\".format(y.shape))\n",
    "        init_loss = sess.run(loss, feed_dict={X: x, Y: y})\n",
    "        print(\"init loss: {}\".format(init_loss))\n",
    "        for i in range(train_iteration_count):\n",
    "            _, step_loss = sess.run([train_op, loss], feed_dict={X: x, Y: y})\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(\"[#{} step: {}] loss: {}\".format(t, i, step_loss))\n",
    "    \n",
    "    #Save check point\n",
    "    saver = tf.train.Saver()\n",
    "    if step_loss < init_loss:\n",
    "        print(\"Saved check point init loss: {} current loss: {}\".format(init_loss, step_loss))\n",
    "        saver.save(sess, ckpt_path)\n",
    "    else:\n",
    "        print(\"Did not make check point. init loss: {} current loss{}\".format(init_loss, step_loss))\n",
    "    \n",
    "    print(\"code: {} {} <= {}\".format(code_to_train, step_loss, init_loss))\n",
    "    \n",
    "    #Compare tarining x and y\n",
    "    predict = sess.run(Y_pred, feed_dict={X: data_x})\n",
    "    prdict_end_prices = predict[:,3:4]\n",
    "    expected_end_prices = data_y[:,3:4]\n",
    "    rmse_val = sess.run(rmse, feed_dict={expected_results: data_y, predictions: predict})\n",
    "    print(\"RMSE: {}  date range: {}~{}\".format(rmse_val, start_date, end_date))\n",
    "\n",
    "    # Both\n",
    "    plt.title('predicted vs expected(actual) prices')\n",
    "    plt.plot(prdict_end_prices)\n",
    "    plt.plot(expected_end_prices)\n",
    "    plt.xlabel(\"Time Period\")\n",
    "    plt.ylabel(\"Stock Price\")\n",
    "    plt.show()    \n",
    "    \n",
    "    print(\"Run test prediction \\n\")   \n",
    "    testCodes = ['005930', \"066570\", '041510']\n",
    "    for index, c in enumerate(testCodes):\n",
    "        runTestData(c, '2018-11-30', '2018-12-01', '2019-01-06', sequence_length, sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
